{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3Hq7YI5nP91",
        "outputId": "8a6790bf-9db0-4c09-b60e-bf308c973ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.7.14)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2.0.2)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.4.post1 netCDF4-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "\n",
        "!pip install netCDF4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import netCDF4 as nc  # Importing netCDF4 library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from netCDF4 import Dataset\n",
        "import h5py"
      ],
      "metadata": {
        "id": "23_PmLsBFfLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Align cellular + behavior data\n",
        "\n",
        "At this point in the pipeline, the behavior and the miniscope timestamps should be aligned and concatened with the EZtrack output. Here we will add the miniscope data to this file, to give all project information (columns) across all frames recorded (rows)."
      ],
      "metadata": {
        "id": "ZsjFYxPeM5_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5FuEu4bf2Xx",
        "outputId": "82057eb1-db69-4af4-da92-cfe45c798f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define where the behavior folder (post-alignment) and the cell data folder are stored\n",
        "\n",
        "behavior_folder = \"/content/drive/MyDrive/Restraint  Ketamine/Stress Ket G2 (n=6) Feb 2024/eztrackwithalignment G2\"\n",
        "\n",
        "cell_data_folder = \"/content/drive/MyDrive/Restraint  Ketamine/Stress Ket G2 (n=6) Feb 2024/MiniAn/5358/Recombination/nc files\""
      ],
      "metadata": {
        "id": "X5aue2CWsGaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Double check file sizes match"
      ],
      "metadata": {
        "id": "sSNms5onET1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract animal ID and session number from filename.\n",
        "def extract_info(filename):\n",
        "    base = os.path.basename(filename)\n",
        "    parts = os.path.splitext(base)[0].split('_')\n",
        "    animal_id = parts[0].replace('minian', '')\n",
        "    session_number = parts[1]\n",
        "    return int(animal_id), session_number\n",
        "\n",
        "\n",
        "def check_variable_lengths(folder_path):\n",
        "    file_lengths = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.nc'):\n",
        "            try:\n",
        "                # Extract animal ID and session number from filename\n",
        "                animal_id, session_number = extract_info(file_name)\n",
        "\n",
        "                # Load the .nc file\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                dataset = nc.Dataset(file_path)\n",
        "\n",
        "                # Load C, A, and S variables\n",
        "                C = dataset.variables['C'][:]\n",
        "                A = dataset.variables['A'][:]\n",
        "                S = dataset.variables['S'][:]\n",
        "\n",
        "                # Get lengths of C, A, and S\n",
        "                C_length = C.shape[1]  # Assuming C is a 2D array, get its width (#frames)\n",
        "                A_length = A.shape[0]  # Assuming A is a 3D array, get its length (# of cells)\n",
        "                S_length = S.shape[1]  # Assuming S is a 2D array, get its width (#frames)\n",
        "\n",
        "                # Close the dataset\n",
        "                dataset.close()\n",
        "\n",
        "                # Append information to list\n",
        "                file_lengths.append((file_name, animal_id, session_number, C_length, A_length, S_length))\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "    return file_lengths\n",
        "\n",
        "# Get lengths of C, A, and S variables for each .nc file in the folder\n",
        "variable_lengths = check_variable_lengths(cell_data_folder)\n",
        "\n",
        "# Print the results\n",
        "for file_name, animal_id, session_number, C_length, A_length, S_length in variable_lengths:\n",
        "    print(f\"File: {file_name}, Animal ID: {animal_id}, Session Number: {session_number}\")\n",
        "    print(f\"Length of C: {C_length}, Length of A: {A_length}, Length of S: {S_length}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn85rXVwpjby",
        "outputId": "459709ac-0278-4389-bb1b-8e53a982e615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: minian5358_s1_minian_dataset_recombined.nc, Animal ID: 5358, Session Number: s1\n",
            "Length of C: 9058, Length of A: 16, Length of S: 9058\n",
            "\n",
            "File: minian5358_s4_minian_dataset_recombined.nc, Animal ID: 5358, Session Number: s4\n",
            "Length of C: 9012, Length of A: 15, Length of S: 9012\n",
            "\n",
            "File: minian5358_s6_minian_dataset_recombined.nc, Animal ID: 5358, Session Number: s6\n",
            "Length of C: 8565, Length of A: 16, Length of S: 8565\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the .nc files\n",
        "folder_path = behavior_folder\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = df.sort_values(by=['Corresponding_Miniscope_Frame'], ascending=True)\n",
        "        final_value = df['Corresponding_Miniscope_Frame'].iloc[-1]\n",
        "        print(f\"Final value in {filename}: {final_value}, size is {df.shape[0]}x{df.shape[1]}\")"
      ],
      "metadata": {
        "id": "I-3CMTCfC3cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde50e79-f1a3-4688-c04f-bcefc58832d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final value in 5358_1_eztrackwithalignment_NAB.csv: 7493, size is 9058x26\n",
            "Final value in 5358_4_eztrackwithalignment_NAB.csv: 9011, size is 9012x26\n",
            "Final value in 5358_6_eztrackwithalignment_NAB.csv: 8564, size is 8565x26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine cell + behavior data into one csv file"
      ],
      "metadata": {
        "id": "hJmkBjTfN3FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract animal ID and session number from filename\n",
        "def extract_info(filename):\n",
        "    base = os.path.basename(filename)  # Get the base filename\n",
        "    parts = os.path.splitext(base)[0].split('_')  # Split by '_' and remove extension\n",
        "    animal_id = parts[0].replace('minian', '')  # Extract animal ID\n",
        "    session_number = parts[1].lstrip('s')  # Remove 's' from the beginning of session number\n",
        "    return int(animal_id), session_number\n",
        "\n",
        "# Function to read behavior data from CSV\n",
        "def read_behavior_data(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    return df\n",
        "\n",
        "# Function to find matching NC file\n",
        "def find_matching_nc_file(animal_id, session_number, nc_files):\n",
        "    for nc_file in nc_files:\n",
        "        animal_id_nc, session_number_nc = extract_info(nc_file)\n",
        "        if animal_id == animal_id_nc and session_number == session_number_nc:\n",
        "            return nc_file\n",
        "    return None\n",
        "\n",
        "# Function to read neural activity data from NC\n",
        "def read_neural_activity(nc_file, cors):\n",
        "    with Dataset(nc_file, 'r') as nc:\n",
        "        neural_data = nc.variables[cors][:]\n",
        "    return neural_data\n",
        "\n",
        "# Define folders\n",
        "target_folder = \"/content/drive/MyDrive/Restraint  Ketamine/Stress Ket G2 (n=6) Feb 2024/C + S \"  # Specify the folder where you want to save the combined CSV files\n",
        "\n",
        "# Get list of files in both folders\n",
        "csv_files = os.listdir(behavior_folder)\n",
        "nc_files = os.listdir(cell_data_folder)\n",
        "\n",
        "# Assuming file names are structured similarly for matching\n",
        "for csv_file in csv_files:\n",
        "    animal_id, session_number = extract_info(csv_file)\n",
        "    matching_nc_file = find_matching_nc_file(animal_id, session_number, nc_files)\n",
        "\n",
        "    if matching_nc_file is not None:\n",
        "        # Read behavior data\n",
        "        behavior_data = read_behavior_data(os.path.join(behavior_folder, csv_file))\n",
        "\n",
        "        # Read neural activity data\n",
        "        neural_data_s = read_neural_activity(os.path.join(cell_data_folder, matching_nc_file), 'S')\n",
        "        neural_data_c = read_neural_activity(os.path.join(cell_data_folder, matching_nc_file), 'C')\n",
        "\n",
        "        # Ensure the alignment based on frame indices\n",
        "        aligned_neural_data_s = []\n",
        "        aligned_neural_data_c = []\n",
        "        for frame_idx in behavior_data['Corresponding_Miniscope_Frame']:\n",
        "            if frame_idx < neural_data_s.shape[1]:\n",
        "                aligned_neural_data_s.append(neural_data_s[:, frame_idx])\n",
        "                aligned_neural_data_c.append(neural_data_c[:, frame_idx])\n",
        "            else:\n",
        "                # Handle case where frame index exceeds neural data length\n",
        "                aligned_neural_data_s.append([np.nan] * neural_data_s.shape[0])  # Placeholder or NaN\n",
        "                aligned_neural_data_c.append([np.nan] * neural_data_c.shape[0])  # Placeholder or NaN\n",
        "\n",
        "        # Convert aligned neural data to DataFrame\n",
        "        aligned_neural_df_s = pd.DataFrame(aligned_neural_data_s, columns=[f'neuron_{i+1}' for i in range(neural_data_s.shape[0])])\n",
        "        aligned_neural_df_c = pd.DataFrame(aligned_neural_data_c, columns=[f'neuron_{i+1}' for i in range(neural_data_c.shape[0])])\n",
        "\n",
        "        # Combine behavior_data and aligned_neural_df into a single DataFrame\n",
        "        combined_data_s = pd.concat([behavior_data.reset_index(drop=True), aligned_neural_df_s], axis=1)\n",
        "        combined_data_c = pd.concat([behavior_data.reset_index(drop=True), aligned_neural_df_c], axis=1)\n",
        "\n",
        "        # Construct the full path to the target CSV file\n",
        "        target_csv_file_s = os.path.join(target_folder, f'{animal_id}_{session_number}_combined_S+beh_NAB.csv')\n",
        "        target_csv_file_c = os.path.join(target_folder, f'{animal_id}_{session_number}_combined_C+beh_NAB.csv')\n",
        "\n",
        "        # Save combined data to the target folder\n",
        "        combined_data_s.to_csv(target_csv_file_s, index=False)\n",
        "        combined_data_c.to_csv(target_csv_file_c, index=False)\n",
        "    else:\n",
        "        print(f\"No matching NC file found for {csv_file}.\")\n"
      ],
      "metadata": {
        "id": "6O4Xy_OKWrNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Rename neuron columns based on CellReg output\n",
        "\n",
        "Before this step, CellReg has been run (by NAB). The entire cellreg folder was uploaded to Drive for each animal.\n",
        "\n",
        "^^ **9/18/24 note, NAB cellreg outpit does not have cell score**\n",
        "\n",
        "- The alignment file (.mat) should be renamed to have the animal id. It it important to note you will need to reference the session order from the log file and manually assign these to the corresponding .csv file that we just generated.\n"
      ],
      "metadata": {
        "id": "JV-sKt0FODM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Duplicate this for each animal. Update the\n",
        "- subject_id\n",
        "-session_order\n",
        "- cellreg file\n",
        "\n",
        "Do not run more than once for each animal. If you accidentally run twice, re-run the previous step."
      ],
      "metadata": {
        "id": "NhJW7SnQ7AVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the subject ID, session numbers, and the folder path\n",
        "subject_id = ['5358']  # Replace with the  subject ID\n",
        "# ^^^ use the cellreg log to get this information\n",
        "folder_path = '/content/drive/MyDrive/Restraint  Ketamine/Stress Ket G2 (n=6) Feb 2024/C + S '  # folder path with cell+beh data\n",
        "cellreg_path = '/content/drive/MyDrive/Restraint  Ketamine/Stress Ket G2 (n=6) Feb 2024/CellReg/5358'\n",
        "\n",
        "for subject in subject_id:\n",
        "  #Loop through the cellsregistered matrix\n",
        "  cellreg_filename = os.path.join(cellreg_path, f'{subject}_cellRegistered.mat')\n",
        "  cellreg = h5py.File(cellreg_filename, 'r')\n",
        "  group = cellreg['cell_registered_struct']\n",
        "  cell_to_index_map = group['cell_to_index_map']\n",
        "  cellsregistered = cell_to_index_map[:]\n",
        "  if subject == '5358':\n",
        "    session_order = [1, 4, 6]\n",
        "  else:\n",
        "    session_order = [1, 2, 4, 6]\n",
        "\n",
        "  for session_index in range(cellsregistered.shape[0]):  # Iterate over the rows\n",
        "      session_num = session_order[session_index]  # Get the corresponding session number\n",
        "      csv_filename_s = os.path.join(folder_path, f\"{subject}_{session_num}_combined_S+beh_NAB.csv\")\n",
        "\n",
        "      if os.path.exists(csv_filename_s):\n",
        "          # Read the CSV file\n",
        "          df = pd.read_csv(csv_filename_s)\n",
        "\n",
        "          # Identify existing cell columns\n",
        "          cell_columns = [col for col in df.columns if col.startswith('neuron_')]\n",
        "          new_header = df.columns.tolist()  # Start with the existing headers\n",
        "\n",
        "          # Update only the cell columns based on cellsregistered for the current session\n",
        "          for index in range(len(cellsregistered[session_index])):  # Iterate over the number of registered cells\n",
        "              cell_index = int(cellsregistered[session_index][index])  # Get the corresponding cell index (which column we need to rename)\n",
        "              #print(cell_index)\n",
        "              if cell_index != 0 and cell_index < len(cell_columns):  # Only rename if the cell is active and within bounds\n",
        "                  #Create a new name for the active cell\n",
        "                  original_column = cell_columns[cell_index-1]  # Get the original column name\n",
        "                  #print (original_column)\n",
        "                  new_header[df.columns.get_loc(original_column)] = f\"neuron_{index + 1}\"  # Update with new name\n",
        "                  #print (new_header[df.columns.get_loc(original_column)])\n",
        "          # Assign the new header to the DataFrame\n",
        "          df.columns = new_header\n",
        "\n",
        "          # Save the updated DataFrame back to the CSV\n",
        "          df.to_csv(csv_filename_s, index=False)\n",
        "      else:\n",
        "          print(f\"File {csv_filename_s} does not exist.\")\n",
        "\n",
        "  #Loop through the cellsregistered matrix\n",
        "  for session_index in range(cellsregistered.shape[0]):  # Iterate over the rows\n",
        "      session_num = session_order[session_index]  # Get the corresponding session number\n",
        "      csv_filename_c = os.path.join(folder_path, f\"{subject}_{session_num}_combined_C+beh_NAB.csv\")\n",
        "\n",
        "      if os.path.exists(csv_filename_c):\n",
        "          # Read the CSV file\n",
        "          df = pd.read_csv(csv_filename_c)\n",
        "\n",
        "          # Identify existing cell columns\n",
        "          cell_columns = [col for col in df.columns if col.startswith('neuron_')]\n",
        "          new_header = df.columns.tolist()  # Start with the existing headers\n",
        "\n",
        "          # Update only the cell columns based on cellsregistered for the current session\n",
        "          for index in range(len(cellsregistered[session_index])):  # Iterate over the number of registered cells\n",
        "              cell_index = int(cellsregistered[session_index][index])  # Get the corresponding cell index (which column we need to rename)\n",
        "              #print(cell_index)\n",
        "              if cell_index != 0 and cell_index < len(cell_columns):  # Only rename if the cell is active and within bounds\n",
        "                  #Create a new name for the active cell\n",
        "                  original_column = cell_columns[cell_index-1]  # Get the original column name\n",
        "                  #print (original_column)\n",
        "                  new_header[df.columns.get_loc(original_column)] = f\"neuron_{index + 1}\"  # Update with new name\n",
        "                  #print (new_header[df.columns.get_loc(original_column)])\n",
        "          # Assign the new header to the DataFrame\n",
        "          df.columns = new_header\n",
        "\n",
        "          # Save the updated DataFrame back to the CSV\n",
        "          df.to_csv(csv_filename_c, index=False)\n",
        "      else:\n",
        "          print(f\"File {csv_filename_c} does not exist.\")"
      ],
      "metadata": {
        "id": "lwXnS2KVhVlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wtIKf3bdDqwX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}